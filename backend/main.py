# backend/main.py - ëª¨ë“ˆí™”ëœ 3ê°œ ì‹œìŠ¤í…œ ì§€ì› ë²„ì „ (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€)

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from starlette.exceptions import HTTPException as StarletteHTTPException
import signal
import sys
import asyncio
import os
import threading
import traceback
import logging
from typing import Dict
from datetime import datetime

# ì¬ê·€ ê¹Šì´ ì¦ê°€ (conversation ì €ì¥ ì‹œ ì¬ê·€ ë¬¸ì œ ë°©ì§€)
sys.setrecursionlimit(5000)

# ë²„í¼ë§ ë¹„í™œì„±í™” - ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥
sys.stdout = sys.stderr = sys.__stdout__

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (ë¡œê¹… ì„¤ì •ë³´ë‹¤ ë¨¼ì €)
os.makedirs('./logs', exist_ok=True)

# ìƒì„¸í•œ ë¡œê¹… ì„¤ì • (force=Trueë¡œ uvicorn ì„¤ì • ë®ì–´ì“°ê¸°)
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
    handlers=[
        logging.FileHandler('./logs/backend_detailed.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ],
    force=True  # uvicornì˜ ê¸°ë³¸ ì„¤ì •ì„ ë®ì–´ì“°ê¸°
)

# argosa ëª¨ë“ˆ ë¡œê¹… ë ˆë²¨ ì„¤ì •
logging.getLogger('routers.argosa').setLevel(logging.DEBUG)
logging.getLogger('routers.argosa.data_collection').setLevel(logging.DEBUG)
logging.getLogger('routers.argosa.shared.firefox_manager').setLevel(logging.DEBUG)

# uvicornê³¼ FastAPI ë¡œê¹… í™œì„±í™”
logging.getLogger('uvicorn').setLevel(logging.DEBUG)
logging.getLogger('uvicorn.access').setLevel(logging.DEBUG)
logging.getLogger('uvicorn.error').setLevel(logging.DEBUG)
logging.getLogger('fastapi').setLevel(logging.DEBUG)

# Local imports
from storage import ensure_directories

# Router imports
from routers import oneai, neuronet, projects
from routers.argosa import router as argosa_router
# search_settings_simple removed - functionality integrated into web_crawler_agent

# argosaì˜ initializeì™€ shutdown í•¨ìˆ˜ëŠ” __init__.pyì—ì„œ exportë˜ì—ˆìœ¼ë¯€ë¡œ ê°™ì´ import
from routers.argosa import initialize as argosa_initialize, shutdown as argosa_shutdown

# ì „ì—­ ë³€ìˆ˜
shutdown_event = asyncio.Event()
background_tasks = []
connected_clients: Dict[str, WebSocket] = {}

# Create FastAPI app
# Modified: 2025-06-29 - Trigger nodemon restart for new search engine endpoints
# Force restart: Search engine settings endpoints added
# Nodemon restart trigger: 2025-06-29 21:17 - COMPLETE FIX - all parts updated
# Fix cache_manager None issue: 2025-06-29 21:50 - Fixed initialize() function
# Final fix: 2025-06-29 21:57 - Direct implementation in main.py working
# LLM Query Settings fix: 2025-06-29 22:15 - Added direct endpoints
# Status endpoint fix: 2025-06-29 22:13 - Force server restart with SystemStateManager fix
# Search settings consolidation: 2025-06-29 - Integrated into web_crawler_agent
app = FastAPI(
    title="3D Animation Automation System", 
    description="AI-powered system for 3D animation production",
    version="1.0.0"
)

# CORS configuration - Firefox Extension ì§€ì›
origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8000",
    "http://127.0.0.1:8000",
    "moz-extension://*",      # Firefox Extension
    "chrome-extension://*",    # Chrome Extension (future support)
]

# Add production URLs if defined
if os.getenv("FRONTEND_URL"):
    origins.append(os.getenv("FRONTEND_URL"))

# Development mode - allow all origins (use with caution)
if os.getenv("DEVELOPMENT_MODE") == "true":
    origins.append("*")

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# HTTP ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = datetime.now()
    
    # ìš”ì²­ ë¡œê¹…
    logger = logging.getLogger("http_requests")
    logger.info(f"ğŸ”¥ HTTP {request.method} {request.url.path} - Headers: {dict(request.headers)}")
    
    # argosa API í˜¸ì¶œì— ëŒ€í•´ì„œëŠ” ë” ìì„¸í•œ ë¡œê¹…
    if "/api/argosa/" in str(request.url.path):
        logger.info(f"ğŸ¯ ARGOSA API CALL: {request.method} {request.url.path}")
        if request.method in ["POST", "PUT", "PATCH"]:
            # ìš”ì²­ bodyë„ ë¡œê¹… (ë„ˆë¬´ í¬ì§€ ì•Šì€ ê²½ìš°)
            try:
                body = await request.body()
                if len(body) < 1000:  # 1KB ë¯¸ë§Œë§Œ ë¡œê¹…
                    logger.info(f"ğŸ¯ Request body: {body.decode('utf-8', errors='ignore')}")
            except:
                pass
    
    response = await call_next(request)
    
    # ì‘ë‹µ ë¡œê¹…
    process_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"ğŸ”¥ Response {response.status_code} for {request.method} {request.url.path} - {process_time:.3f}s")
    
    return response

# Exception handler for HTTP exceptions to ensure CORS headers are included
@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

# General exception handler for unhandled errors
@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger = logging.getLogger(__name__)
    logger.error(f"Unhandled exception: {exc}")
    logger.error(traceback.format_exc())
    
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error", "error": str(exc)},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

# Removed override - will fix in the actual endpoint

# Include routers
app.include_router(oneai.router, prefix="/api/oneai", tags=["One AI"])
app.include_router(argosa_router)  # prefixì™€ tagsëŠ” argosa_router ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
app.include_router(neuronet.router, prefix="/api/neuronet", tags=["NeuroNet"])
app.include_router(projects.router, prefix="/projects", tags=["Projects"])
# Search settings are now handled by web_crawler_agent in argosa router
print(f"[DEBUG] Argosa router paths: {[r.path for r in argosa_router.routes]}", flush=True)

# Debug endpoint to list all routes
@app.get("/debug/routes")
async def list_routes():
    routes = []
    for route in app.routes:
        if hasattr(route, "path") and hasattr(route, "methods"):
            routes.append({
                "path": route.path,
                "methods": list(route.methods) if route.methods else [],
                "name": route.name
            })
    return {"total": len(routes), "routes": sorted(routes, key=lambda x: x["path"])}

# Root endpoint
@app.get("/")
async def root():
    print("[API] Root endpoint called", flush=True)
    return {
        "message": "3D Animation Automation System API",
        "systems": {
            "oneai": "AI Production Pipeline",
            "argosa": "Information Analysis & Prediction",
            "neuronet": "AI Training Automation"
        },
        "version": "1.0.0"
    }

# Health check endpoint
@app.get("/health")
async def health_check():
    print("[API] Health check called", flush=True)
    return {
        "status": "healthy",
        "systems": {
            "oneai": "operational",
            "argosa": "operational",
            "neuronet": "development"
        }
    }

# Search engine settings endpoints are now handled by web_crawler_agent
# Available at:
# GET  /api/argosa/data/settings
# PUT  /api/argosa/data/settings
# GET  /api/argosa/data/stats
# POST /api/argosa/data/stats/record

# ======================== LLM Query Settings - Direct Implementation ========================

@app.get("/api/argosa/data/llm/query/settings")
async def get_llm_query_settings_direct():
    """LLM Query ì„¤ì • ê°€ì ¸ì˜¤ê¸° - ì§ì ‘ êµ¬í˜„"""
    import json
    from pathlib import Path
    try:
        backend_path = Path(__file__).parent
        settings_path = backend_path / "routers" / "argosa" / "collection" / "settings" / "llm_query_settings.json"
        
        if settings_path.exists():
            with open(settings_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)
            return settings
        else:
            # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
            default_settings = {
                "auto_query_enabled": True,
                "max_queries_per_analysis": 5,
                "allowed_providers": ["chatgpt", "claude", "gemini"],
                "query_timeout": 30,
                "firefox_visible": True
            }
            return default_settings
    except Exception as e:
        print(f"âŒ Failed to get LLM query settings: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/argosa/data/llm/query/settings")
async def update_llm_query_settings_direct(settings: dict):
    """LLM Query ì„¤ì • ì—…ë°ì´íŠ¸ - ì§ì ‘ êµ¬í˜„"""
    import json
    from pathlib import Path
    try:
        backend_path = Path(__file__).parent
        settings_path = backend_path / "routers" / "argosa" / "collection" / "settings" / "llm_query_settings.json"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        settings_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ì €ì¥
        with open(settings_path, 'w', encoding='utf-8') as f:
            json.dump(settings, f, indent=2, ensure_ascii=False)
            
        print(f"âœ… LLM query settings updated: {settings}", flush=True)
        return settings
        
    except Exception as e:
        print(f"âŒ Failed to update LLM query settings: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/argosa/data/llm/query/activities")
async def get_llm_query_activities_direct():
    """LLM Query í™œë™ ë‚´ì—­ ê°€ì ¸ì˜¤ê¸° - ì§ì ‘ êµ¬í˜„"""
    return {"activities": []}

@app.get("/api/argosa/data/llm/query/analysis/status")
async def get_llm_analysis_status_direct():
    """LLM ë¶„ì„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° - ì§ì ‘ êµ¬í˜„"""
    return {
        "current_analysis": None,
        "queries_sent": 0,
        "queries_completed": 0,
        "last_query_time": None,
        "analysis_progress": 0
    }

@app.get("/api/argosa/data/llm/query/stats")
async def get_llm_query_stats_direct():
    """LLM Query í†µê³„ ê°€ì ¸ì˜¤ê¸° - ì§ì ‘ êµ¬í˜„"""
    return {}

@app.delete("/api/argosa/data/llm/query/activities/clear")
async def clear_llm_query_activities_direct():
    """ì™„ë£Œëœ LLM Query í™œë™ ë‚´ì—­ ì‚­ì œ - ì§ì ‘ êµ¬í˜„"""
    return {"success": True}

@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë²”ìš© WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    connected_clients[client_id] = websocket
    
    try:
        print(f"[WebSocket] Client {client_id} connected", flush=True)
        
        # ì´ˆê¸° ë©”ì‹œì§€ ì „ì†¡
        await websocket.send_json({
            "type": "connection",
            "status": "connected",
            "client_id": client_id,
            "message": "Successfully connected to server"
        })
        
        # ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°
        while True:
            data = await websocket.receive_json()
            
            # Echo back ë˜ëŠ” ë‹¤ë¥¸ ì²˜ë¦¬
            await websocket.send_json({
                "type": "echo",
                "data": data
            })
                
    except WebSocketDisconnect:
        print(f"[WebSocket] Client {client_id} disconnected", flush=True)
    finally:
        if client_id in connected_clients:
            del connected_clients[client_id]
            
# Shutdown í•¸ë“¤ëŸ¬
def handle_shutdown(sig, frame):
    """Ctrl+C ì‹œ ì¦‰ì‹œ ì¢…ë£Œ"""
    print("\n[Shutdown] Immediate shutdown requested...", flush=True)
    
    # ê°•ì œ ì¢…ë£Œ ëª¨ë“œ
    if hasattr(sys, '_is_shutting_down'):
        # ë‘ ë²ˆì§¸ Ctrl+CëŠ” ì¦‰ì‹œ ì¢…ë£Œ
        print("[Shutdown] Force quit!", flush=True)
        os._exit(0)
    
    sys._is_shutting_down = True
    
    # ë¹„ë™ê¸° ì‘ì—… ì—†ì´ ë°”ë¡œ ì¢…ë£Œ
    try:
        # shutdown_eventë§Œ ì„¤ì •
        shutdown_event.set()
        
        # ëª¨ë“  íƒœìŠ¤í¬ ì¦‰ì‹œ ì·¨ì†Œ
        loop = asyncio.get_event_loop()
        for task in asyncio.all_tasks(loop):
            task.cancel()
        
        # 1ì´ˆ í›„ ê°•ì œ ì¢…ë£Œ
        def force_exit():
            print("[Shutdown] Force exit after timeout", flush=True)
            os._exit(0)
        
        timer = threading.Timer(1.0, force_exit)
        timer.start()
        
    except Exception:
        os._exit(0)

# Signal í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, handle_shutdown)
signal.signal(signal.SIGTERM, handle_shutdown)

# Windowsì˜ ê²½ìš° ì¶”ê°€ í•¸ë“¤ëŸ¬
if sys.platform == "win32":
    signal.signal(signal.SIGBREAK, handle_shutdown)

# Startup event
@app.on_event("startup")
async def startup_event():
    """Initialize all systems on startup"""
    print("[Startup] Initializing 3D Animation Automation System...", flush=True)
    
    # Ensure required directories exist
    ensure_directories()
    
    try:
        # Initialize One AI system
        print("[Startup] Initializing One AI system...", flush=True)
        try:
            await oneai.initialize()
            print("[Startup] One AI initialized successfully", flush=True)
        except Exception as e:
            print(f"[Startup] One AI initialization error: {e}", flush=True)
            print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
            # One AIëŠ” ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
        
        # Initialize Argosa system
        print("[Startup] Initializing Argosa system...", flush=True)
        try:
            await argosa_initialize()
            print("[Startup] Argosa initialized successfully", flush=True)
            
            # Argosa ì´ˆê¸°í™” í›„ LLM trackerì™€ conversation_saver ì—°ê²°
            try:
                from routers.argosa.shared.llm_tracker import llm_tracker
                from routers.argosa.shared.conversation_saver import conversation_saver
                
                conversation_saver.set_llm_tracker(llm_tracker)
                print("[Startup] LLM tracker registered with conversation_saver", flush=True)
                
                # LLM tracker í†µê³„ ì¶œë ¥
                stats = await llm_tracker.get_stats()
                print(f"[Startup] LLM tracker stats: {stats['total_tracked']} tracked conversations", flush=True)
                
            except ImportError as e:
                print(f"[Startup] Warning: Could not setup LLM tracker integration: {e}", flush=True)
                # LLM trackerëŠ” ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
            except Exception as e:
                print(f"[Startup] Error setting up LLM tracker: {e}", flush=True)
                print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
            
            # Firefox Manager ì´ˆê¸°í™”
            try:
                from routers.argosa.shared.firefox_manager import get_firefox_manager
                
                firefox_manager = get_firefox_manager()
                if await firefox_manager.initialize():
                    print("[Startup] Firefox Manager initialized successfully", flush=True)
                    
                    # Firefox ìƒíƒœ í™•ì¸
                    info = await firefox_manager.get_info()
                    print(f"[Startup] Firefox Manager status: {info.get('status')}", flush=True)
                    print(f"[Startup] Firefox running: {info.get('is_running')}", flush=True)
                    if info.get('pid'):
                        print(f"[Startup] Firefox PID: {info.get('pid')}", flush=True)
                else:
                    print("[Startup] Firefox Manager initialization failed", flush=True)
                    
            except ImportError as e:
                print(f"[Startup] Warning: Could not setup Firefox Manager: {e}", flush=True)
                # Firefox ManagerëŠ” ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
            except Exception as e:
                print(f"[Startup] Error setting up Firefox Manager: {e}", flush=True)
                print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
            
        except Exception as e:
            print(f"[Startup] Argosa initialization error: {e}", flush=True)
            print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
            # ArgosaëŠ” í•„ìˆ˜ì´ë¯€ë¡œ ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ
            raise
        
        # Initialize NeuroNet system
        print("[Startup] Initializing NeuroNet system...", flush=True)
        try:
            await neuronet.initialize()
            print("[Startup] NeuroNet initialized successfully", flush=True)
        except Exception as e:
            print(f"[Startup] NeuroNet initialization error: {e}", flush=True)
            print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
            # NeuroNetì€ ê°œë°œ ì¤‘ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
        
        print("[Startup] All systems initialization completed", flush=True)
        
        # OneAI periodic taskê°€ ìˆë‹¤ë©´ ì¶”ê°€
        try:
            if hasattr(oneai, 'start_periodic_tasks'):
                print("[Startup] Starting OneAI periodic tasks...", flush=True)
                task = asyncio.create_task(oneai.start_periodic_tasks(shutdown_event))
                background_tasks.append(task)
                print("[Startup] OneAI periodic tasks started", flush=True)
        except Exception as e:
            print(f"[Startup] Error starting periodic tasks: {e}", flush=True)
            # ì£¼ê¸°ì  ì‘ì—…ì€ ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
            
        print("[Startup] Application startup completed successfully", flush=True)
        
    except Exception as e:
        print(f"[Startup] Critical error during initialization: {e}", flush=True)
        print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ
        sys.exit(1)

# Shutdown event
@app.on_event("shutdown")
async def shutdown_handler():
    """Cleanup all systems on shutdown"""
    print("[Shutdown] FastAPI shutdown event triggered...", flush=True)
    
    # shutdown_event ì„¤ì •
    shutdown_event.set()
    
    try:
        # 1. ë¨¼ì € ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¦‰ì‹œ ì·¨ì†Œ
        if background_tasks:
            print("[Shutdown] Cancelling background tasks...", flush=True)
            for task in background_tasks:
                task.cancel()
            
            # íƒœìŠ¤í¬ ì·¨ì†Œ ëŒ€ê¸° (ì§§ì€ timeout)
            try:
                await asyncio.wait_for(
                    asyncio.gather(*background_tasks, return_exceptions=True),
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                print("[Shutdown] Background tasks cancellation timeout", flush=True)
        
        # 2. ëª¨ë“  ì‹œìŠ¤í…œ ë™ì‹œì— shutdown (ë³‘ë ¬ ì²˜ë¦¬)
        print("[Shutdown] Shutting down all systems simultaneously...", flush=True)
        
        shutdown_tasks = []
        
        # OneAI shutdown (save ì—†ì´ ë¹ ë¥¸ ì¢…ë£Œ)
        async def quick_oneai_shutdown():
            try:
                print("[Shutdown] Shutting down OneAI...", flush=True)
                # save ì‘ì—… ê±´ë„ˆë›°ê¸° ì˜µì…˜
                if hasattr(oneai, 'quick_shutdown'):
                    await oneai.quick_shutdown()
                else:
                    await asyncio.wait_for(oneai.shutdown(), timeout=2.0)
                print("[Shutdown] OneAI shutdown completed", flush=True)
            except asyncio.TimeoutError:
                print("[Shutdown] OneAI shutdown timeout - forcing", flush=True)
            except Exception as e:
                print(f"[Shutdown] OneAI error: {e}", flush=True)
        
        # Argosa shutdown with LLM tracker and Firefox cleanup
        async def quick_argosa_shutdown():
            try:
                print("[Shutdown] Shutting down Argosa...", flush=True)
                
                # Firefox Manager cleanup
                try:
                    from routers.argosa.shared.firefox_manager import get_firefox_manager
                    firefox_manager = get_firefox_manager()
                    await firefox_manager.cleanup()
                    print("[Shutdown] Firefox Manager cleaned up", flush=True)
                except Exception as e:
                    print(f"[Shutdown] Firefox cleanup error: {e}", flush=True)
                
                # LLM tracker ìƒíƒœ ì €ì¥ (ì˜µì…˜)
                try:
                    from routers.argosa.shared.llm_tracker import llm_tracker
                    await llm_tracker._save_state()
                    print("[Shutdown] LLM tracker state saved", flush=True)
                except:
                    pass  # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                
                await asyncio.wait_for(argosa_shutdown(), timeout=1.0)
                print("[Shutdown] Argosa shutdown completed", flush=True)
            except asyncio.TimeoutError:
                print("[Shutdown] Argosa shutdown timeout", flush=True)
            except Exception as e:
                print(f"[Shutdown] Argosa error: {e}", flush=True)
        
        # NeuroNet shutdown
        async def quick_neuronet_shutdown():
            try:
                print("[Shutdown] Shutting down NeuroNet...", flush=True)
                await asyncio.wait_for(neuronet.shutdown(), timeout=1.0)
                print("[Shutdown] NeuroNet shutdown completed", flush=True)
            except asyncio.TimeoutError:
                print("[Shutdown] NeuroNet shutdown timeout", flush=True)
            except Exception as e:
                print(f"[Shutdown] NeuroNet error: {e}", flush=True)
        
        # ê° ì‹œìŠ¤í…œ shutdown task ìƒì„±
        shutdown_tasks.append(asyncio.create_task(quick_oneai_shutdown()))
        shutdown_tasks.append(asyncio.create_task(quick_argosa_shutdown()))
        shutdown_tasks.append(asyncio.create_task(quick_neuronet_shutdown()))
        
        # ëª¨ë“  shutdown ë™ì‹œ ì‹¤í–‰ (ìµœëŒ€ 3ì´ˆ ëŒ€ê¸°)
        await asyncio.wait_for(
            asyncio.gather(*shutdown_tasks, return_exceptions=True),
            timeout=3.0
        )
        
        print("[Shutdown] All systems shut down", flush=True)
        
    except asyncio.TimeoutError:
        print("[Shutdown] Timeout - forcing shutdown", flush=True)
    except Exception as e:
        print(f"[Shutdown] Error: {e}", flush=True)
        print(f"[Shutdown] Traceback: {traceback.format_exc()}", flush=True)

@app.get("/debug/routes")
async def debug_routes():
    """ëª¨ë“  ë“±ë¡ëœ ë¼ìš°íŠ¸ í™•ì¸"""
    print("[DEBUG] Routes endpoint called", flush=True)
    routes = []
    for route in app.routes:
        if hasattr(route, "path"):
            routes.append({
                "path": route.path,
                "methods": list(route.methods) if hasattr(route, "methods") else []
            })
    return {"routes": routes}

# Removed test endpoint


# Removed test endpoint

# Removed duplicate endpoint

@app.get("/debug/llm-tracker")
async def debug_llm_tracker():
    """LLM tracker ìƒíƒœ í™•ì¸"""
    try:
        from routers.argosa.shared.llm_tracker import llm_tracker
        stats = await llm_tracker.get_stats()
        return {
            "status": "operational",
            "stats": stats
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    import logging
    
    # ëª¨ë“  uvicorn ê´€ë ¨ ë¡œê±° ë¹„í™œì„±í™”
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.error").setLevel(logging.INFO)
    
    # ë˜ëŠ” íŠ¹ì • í•¸ë“¤ëŸ¬ ì œê±°
    uvicorn_logger = logging.getLogger("uvicorn.access")
    uvicorn_logger.handlers = []
    uvicorn_logger.propagate = False
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="warning"
    )
