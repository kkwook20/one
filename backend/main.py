# backend/main.py - ëª¨ë“ˆí™”ëœ 3ê°œ ì‹œìŠ¤í…œ ì§€ì› ë²„ì „ (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€)

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from starlette.exceptions import HTTPException as StarletteHTTPException
import signal
import sys
import asyncio
import os
import threading
import traceback
import logging
from typing import Dict
from datetime import datetime

# ì¬ê·€ ê¹Šì´ ì¦ê°€ (conversation ì €ì¥ ì‹œ ì¬ê·€ ë¬¸ì œ ë°©ì§€)
sys.setrecursionlimit(5000)

# ë²„í¼ë§ ë¹„í™œì„±í™” - ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥
sys.stdout = sys.stderr = sys.__stdout__

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (ë¡œê¹… ì„¤ì •ë³´ë‹¤ ë¨¼ì €)
os.makedirs('./logs', exist_ok=True)

# ìƒì„¸í•œ ë¡œê¹… ì„¤ì • (force=Trueë¡œ uvicorn ì„¤ì • ë®ì–´ì“°ê¸°)
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
    handlers=[
        logging.FileHandler('./logs/backend_detailed.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ],
    force=True  # uvicornì˜ ê¸°ë³¸ ì„¤ì •ì„ ë®ì–´ì“°ê¸°
)

# DISABLED: argosa logging for ONE AI focus
# logging.getLogger('routers.argosa').setLevel(logging.DEBUG)
# logging.getLogger('routers.argosa.data_collection').setLevel(logging.DEBUG)
# logging.getLogger('routers.argosa.shared.firefox_manager').setLevel(logging.DEBUG)

# uvicornê³¼ FastAPI ë¡œê¹… í™œì„±í™”
logging.getLogger('uvicorn').setLevel(logging.DEBUG)
logging.getLogger('uvicorn.access').setLevel(logging.DEBUG)
logging.getLogger('uvicorn.error').setLevel(logging.DEBUG)
logging.getLogger('fastapi').setLevel(logging.DEBUG)

# Local imports
from storage import ensure_directories

# Router imports
from routers import oneai, projects
# DISABLED: neuronet and argosa for ONE AI focus
# from routers import neuronet
# from routers.argosa import router as argosa_router
# from routers.argosa import initialize as argosa_initialize, shutdown as argosa_shutdown

# ì „ì—­ ë³€ìˆ˜
shutdown_event = asyncio.Event()
background_tasks = []
connected_clients: Dict[str, WebSocket] = {}

# Create FastAPI app
# Modified: 2025-06-29 - Trigger nodemon restart for new search engine endpoints
# Force restart: Search engine settings endpoints added
# Nodemon restart trigger: 2025-06-29 21:17 - COMPLETE FIX - all parts updated
# Fix cache_manager None issue: 2025-06-29 21:50 - Fixed initialize() function
# Final fix: 2025-06-29 21:57 - Direct implementation in main.py working
# LLM Query Settings fix: 2025-06-29 22:15 - Added direct endpoints
# Status endpoint fix: 2025-06-29 22:13 - Force server restart with SystemStateManager fix
# Search settings consolidation: 2025-06-29 - Integrated into web_crawler_agent
app = FastAPI(
    title="3D Animation Automation System", 
    description="AI-powered system for 3D animation production",
    version="1.0.0"
)

# CORS configuration - Firefox Extension ì§€ì›
origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8000",
    "http://127.0.0.1:8000",
    "moz-extension://*",      # Firefox Extension
    "chrome-extension://*",    # Chrome Extension (future support)
]

# Add production URLs if defined
if os.getenv("FRONTEND_URL"):
    origins.append(os.getenv("FRONTEND_URL"))

# Development mode - allow all origins (use with caution)
if os.getenv("DEVELOPMENT_MODE") == "true":
    origins.append("*")

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# HTTP ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = datetime.now()
    
    # ìš”ì²­ ë¡œê¹…
    logger = logging.getLogger("http_requests")
    logger.info(f"ğŸ”¥ HTTP {request.method} {request.url.path} - Headers: {dict(request.headers)}")
    
    # ONE AI API í˜¸ì¶œì— ëŒ€í•´ì„œëŠ” ë” ìì„¸í•œ ë¡œê¹…
    if "/api/oneai/" in str(request.url.path):
        logger.info(f"ğŸ¯ ONE AI API CALL: {request.method} {request.url.path}")
        if request.method in ["POST", "PUT", "PATCH"]:
            # ìš”ì²­ bodyë„ ë¡œê¹… (ë„ˆë¬´ í¬ì§€ ì•Šì€ ê²½ìš°)
            try:
                body = await request.body()
                if len(body) < 1000:  # 1KB ë¯¸ë§Œë§Œ ë¡œê¹…
                    logger.info(f"ğŸ¯ Request body: {body.decode('utf-8', errors='ignore')}")
            except:
                pass
    
    response = await call_next(request)
    
    # ì‘ë‹µ ë¡œê¹…
    process_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"ğŸ”¥ Response {response.status_code} for {request.method} {request.url.path} - {process_time:.3f}s")
    
    return response

# Exception handler for HTTP exceptions to ensure CORS headers are included
@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

# General exception handler for unhandled errors
@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger = logging.getLogger(__name__)
    logger.error(f"Unhandled exception: {exc}")
    logger.error(traceback.format_exc())
    
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error", "error": str(exc)},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

# Removed override - will fix in the actual endpoint

# Include routers - ONE AI focus
app.include_router(oneai.router, prefix="/api/oneai", tags=["One AI"])
app.include_router(projects.router, prefix="/projects", tags=["Projects"])
# DISABLED: argosa and neuronet routers
# app.include_router(argosa_router)
# app.include_router(neuronet.router, prefix="/api/neuronet", tags=["NeuroNet"])

# Debug endpoint to list all routes
@app.get("/debug/routes")
async def list_routes():
    routes = []
    for route in app.routes:
        if hasattr(route, "path") and hasattr(route, "methods"):
            routes.append({
                "path": route.path,
                "methods": list(route.methods) if route.methods else [],
                "name": route.name
            })
    return {"total": len(routes), "routes": sorted(routes, key=lambda x: x["path"])}

# Root endpoint
@app.get("/")
async def root():
    print("[API] Root endpoint called", flush=True)
    return {
        "message": "ONE AI System API",
        "systems": {
            "oneai": "AI Production Pipeline (Active)",
            "argosa": "Information Analysis & Prediction (Disabled)",
            "neuronet": "AI Training Automation (Disabled)"
        },
        "version": "1.0.0",
        "focus": "ONE AI Development Mode"
    }

# Health check endpoint
@app.get("/health")
async def health_check():
    print("[API] Health check called", flush=True)
    return {
        "status": "healthy",
        "systems": {
            "oneai": "operational",
            "argosa": "disabled",
            "neuronet": "disabled"
        },
        "mode": "ONE AI Focus"
    }

# DISABLED: Search engine settings endpoints (part of Argosa system)
# To re-enable, uncomment argosa router imports

# DISABLED: LLM Query endpoints for Argosa
# These endpoints are disabled in ONE AI focus mode
# To re-enable, uncomment this section and the argosa router imports

@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë²”ìš© WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    connected_clients[client_id] = websocket
    
    try:
        print(f"[WebSocket] Client {client_id} connected", flush=True)
        
        # ì´ˆê¸° ë©”ì‹œì§€ ì „ì†¡
        await websocket.send_json({
            "type": "connection",
            "status": "connected",
            "client_id": client_id,
            "message": "Successfully connected to server"
        })
        
        # ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°
        while True:
            data = await websocket.receive_json()
            
            # Echo back ë˜ëŠ” ë‹¤ë¥¸ ì²˜ë¦¬
            await websocket.send_json({
                "type": "echo",
                "data": data
            })
                
    except WebSocketDisconnect:
        print(f"[WebSocket] Client {client_id} disconnected", flush=True)
    finally:
        if client_id in connected_clients:
            del connected_clients[client_id]
            
# Shutdown í•¸ë“¤ëŸ¬
def handle_shutdown(sig, frame):
    """Ctrl+C ì‹œ ì¦‰ì‹œ ì¢…ë£Œ"""
    print("\n[Shutdown] Immediate shutdown requested...", flush=True)
    
    # ê°•ì œ ì¢…ë£Œ ëª¨ë“œ
    if hasattr(sys, '_is_shutting_down'):
        # ë‘ ë²ˆì§¸ Ctrl+CëŠ” ì¦‰ì‹œ ì¢…ë£Œ
        print("[Shutdown] Force quit!", flush=True)
        os._exit(0)
    
    sys._is_shutting_down = True
    
    # ë¹„ë™ê¸° ì‘ì—… ì—†ì´ ë°”ë¡œ ì¢…ë£Œ
    try:
        # shutdown_eventë§Œ ì„¤ì •
        shutdown_event.set()
        
        # ëª¨ë“  íƒœìŠ¤í¬ ì¦‰ì‹œ ì·¨ì†Œ
        loop = asyncio.get_event_loop()
        for task in asyncio.all_tasks(loop):
            task.cancel()
        
        # 1ì´ˆ í›„ ê°•ì œ ì¢…ë£Œ
        def force_exit():
            print("[Shutdown] Force exit after timeout", flush=True)
            os._exit(0)
        
        timer = threading.Timer(1.0, force_exit)
        timer.start()
        
    except Exception:
        os._exit(0)

# Signal í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, handle_shutdown)
signal.signal(signal.SIGTERM, handle_shutdown)

# Windowsì˜ ê²½ìš° ì¶”ê°€ í•¸ë“¤ëŸ¬
if sys.platform == "win32":
    signal.signal(signal.SIGBREAK, handle_shutdown)

# Startup event
@app.on_event("startup")
async def startup_event():
    """Initialize all systems on startup"""
    print("[Startup] Initializing 3D Animation Automation System...", flush=True)
    
    # Ensure required directories exist
    ensure_directories()
    
    try:
        # Initialize One AI system
        print("[Startup] Initializing One AI system...", flush=True)
        try:
            await oneai.initialize()
            print("[Startup] One AI initialized successfully", flush=True)
        except Exception as e:
            print(f"[Startup] One AI initialization error: {e}", flush=True)
            print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
            # One AIëŠ” ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
        
        # DISABLED: Argosa system initialization
        # print("[Startup] Argosa system disabled in ONE AI focus mode")
        
        # DISABLED: NeuroNet system initialization
        # print("[Startup] NeuroNet system disabled in ONE AI focus mode")
        
        print("[Startup] All systems initialization completed", flush=True)
        
        # OneAI periodic taskê°€ ìˆë‹¤ë©´ ì¶”ê°€
        try:
            if hasattr(oneai, 'start_periodic_tasks'):
                print("[Startup] Starting OneAI periodic tasks...", flush=True)
                task = asyncio.create_task(oneai.start_periodic_tasks(shutdown_event))
                background_tasks.append(task)
                print("[Startup] OneAI periodic tasks started", flush=True)
        except Exception as e:
            print(f"[Startup] Error starting periodic tasks: {e}", flush=True)
            # ì£¼ê¸°ì  ì‘ì—…ì€ ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
            
        print("[Startup] Application startup completed successfully", flush=True)
        
    except Exception as e:
        print(f"[Startup] Critical error during initialization: {e}", flush=True)
        print(f"[Startup] Traceback: {traceback.format_exc()}", flush=True)
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ
        sys.exit(1)

# Shutdown event
@app.on_event("shutdown")
async def shutdown_handler():
    """Cleanup all systems on shutdown"""
    print("[Shutdown] FastAPI shutdown event triggered...", flush=True)
    
    # shutdown_event ì„¤ì •
    shutdown_event.set()
    
    try:
        # 1. ë¨¼ì € ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¦‰ì‹œ ì·¨ì†Œ
        if background_tasks:
            print("[Shutdown] Cancelling background tasks...", flush=True)
            for task in background_tasks:
                task.cancel()
            
            # íƒœìŠ¤í¬ ì·¨ì†Œ ëŒ€ê¸° (ì§§ì€ timeout)
            try:
                await asyncio.wait_for(
                    asyncio.gather(*background_tasks, return_exceptions=True),
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                print("[Shutdown] Background tasks cancellation timeout", flush=True)
        
        # 2. ëª¨ë“  ì‹œìŠ¤í…œ ë™ì‹œì— shutdown (ë³‘ë ¬ ì²˜ë¦¬)
        print("[Shutdown] Shutting down all systems simultaneously...", flush=True)
        
        shutdown_tasks = []
        
        # OneAI shutdown (save ì—†ì´ ë¹ ë¥¸ ì¢…ë£Œ)
        async def quick_oneai_shutdown():
            try:
                print("[Shutdown] Shutting down OneAI...", flush=True)
                # save ì‘ì—… ê±´ë„ˆë›°ê¸° ì˜µì…˜
                if hasattr(oneai, 'quick_shutdown'):
                    await oneai.quick_shutdown()
                else:
                    await asyncio.wait_for(oneai.shutdown(), timeout=2.0)
                print("[Shutdown] OneAI shutdown completed", flush=True)
            except asyncio.TimeoutError:
                print("[Shutdown] OneAI shutdown timeout - forcing", flush=True)
            except Exception as e:
                print(f"[Shutdown] OneAI error: {e}", flush=True)
        
        # DISABLED: Argosa and NeuroNet shutdown
        # These systems are disabled in ONE AI focus mode
        
        # ê° ì‹œìŠ¤í…œ shutdown task ìƒì„± - ONE AI only
        shutdown_tasks.append(asyncio.create_task(quick_oneai_shutdown()))
        # DISABLED: Argosa and NeuroNet shutdown tasks
        # shutdown_tasks.append(asyncio.create_task(quick_argosa_shutdown()))
        # shutdown_tasks.append(asyncio.create_task(quick_neuronet_shutdown()))
        
        # ëª¨ë“  shutdown ë™ì‹œ ì‹¤í–‰ (ìµœëŒ€ 3ì´ˆ ëŒ€ê¸°)
        await asyncio.wait_for(
            asyncio.gather(*shutdown_tasks, return_exceptions=True),
            timeout=3.0
        )
        
        print("[Shutdown] All systems shut down", flush=True)
        
    except asyncio.TimeoutError:
        print("[Shutdown] Timeout - forcing shutdown", flush=True)
    except Exception as e:
        print(f"[Shutdown] Error: {e}", flush=True)
        print(f"[Shutdown] Traceback: {traceback.format_exc()}", flush=True)

@app.get("/debug/routes")
async def debug_routes():
    """ëª¨ë“  ë“±ë¡ëœ ë¼ìš°íŠ¸ í™•ì¸"""
    print("[DEBUG] Routes endpoint called", flush=True)
    routes = []
    for route in app.routes:
        if hasattr(route, "path"):
            routes.append({
                "path": route.path,
                "methods": list(route.methods) if hasattr(route, "methods") else []
            })
    return {"routes": routes}

# Removed test endpoint


# Removed test endpoint

# Removed duplicate endpoint

# DISABLED: Debug endpoints for Argosa
# @app.get("/debug/llm-tracker")
# async def debug_llm_tracker():
#     """LLM tracker ìƒíƒœ í™•ì¸"""
#     return {"status": "disabled", "message": "Argosa system disabled in ONE AI focus mode"}

if __name__ == "__main__":
    import uvicorn
    import logging
    
    # ëª¨ë“  uvicorn ê´€ë ¨ ë¡œê±° ë¹„í™œì„±í™”
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.error").setLevel(logging.INFO)
    
    # ë˜ëŠ” íŠ¹ì • í•¸ë“¤ëŸ¬ ì œê±°
    uvicorn_logger = logging.getLogger("uvicorn.access")
    uvicorn_logger.handlers = []
    uvicorn_logger.propagate = False
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="warning"
    )
